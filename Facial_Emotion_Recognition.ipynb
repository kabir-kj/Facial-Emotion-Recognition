{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6j/MwiuFOal5ALqmjiw//",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kabir-kj/Facial-Emotion-Recognition/blob/main/Facial_Emotion_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow keras opencv-python-headless"
      ],
      "metadata": {
        "id": "MoRSlFAA5BE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20VDoxDU35PS"
      },
      "outputs": [],
      "source": [
        "#Data Collection and Preprocessing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load the FER-2013 dataset from Kaggle (assuming you've already downloaded it and uploaded to your Google Drive)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/fer2013/fer2013.csv')\n",
        "\n",
        "# Split the data into training, validation, and test sets\n",
        "def load_fer2013():\n",
        "    X_train, y_train, X_val, y_val, X_test, y_test = [], [], [], [], [], []\n",
        "    for index, row in data.iterrows():\n",
        "        pixels = np.array(row['pixels'].split(), dtype='float32')\n",
        "        emotion = row['emotion']\n",
        "        if row['Usage'] == 'Training':\n",
        "            X_train.append(pixels)\n",
        "            y_train.append(emotion)\n",
        "        elif row['Usage'] == 'PublicTest':\n",
        "            X_val.append(pixels)\n",
        "            y_val.append(emotion)\n",
        "        else:\n",
        "            X_test.append(pixels)\n",
        "            y_test.append(emotion)\n",
        "\n",
        "    X_train = np.array(X_train).reshape(-1, 48, 48, 1)\n",
        "    X_val = np.array(X_val).reshape(-1, 48, 48, 1)\n",
        "    X_test = np.array(X_test).reshape(-1, 48, 48, 1)\n",
        "\n",
        "    y_train = to_categorical(y_train, 7)\n",
        "    y_val = to_categorical(y_val, 7)\n",
        "    y_test = to_categorical(y_test, 7)\n",
        "\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
        "\n",
        "X_train, y_train, X_val, y_val, X_test, y_test = load_fer2013()\n",
        "\n",
        "# Normalize the pixel values\n",
        "X_train /= 255.0\n",
        "X_val /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "# Data Augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "datagen.fit(X_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#feature extraction and model build\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(7, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(datagen.flow(X_train, y_train, batch_size=64),\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    epochs=50)\n",
        "\n"
      ],
      "metadata": {
        "id": "wFvT1MZR4D1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f'Test accuracy: {test_acc}')\n"
      ],
      "metadata": {
        "id": "6GZjJmRZ4D5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def emotion_recognition():\n",
        "    emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
        "\n",
        "    cap = cv2.VideoCapture(0)\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        faces = detect_faces(gray_frame)\n",
        "\n",
        "        for (x, y, w, h) in faces:\n",
        "            face = gray_frame[y:y+h, x:x+w]\n",
        "            face = cv2.resize(face, (48, 48))\n",
        "            face = face.reshape(1, 48, 48, 1) / 255.0\n",
        "            emotion = model.predict(face)\n",
        "            emotion_label = emotion_labels[np.argmax(emotion)]\n",
        "            cv2.putText(frame, emotion_label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
        "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
        "\n",
        "        cv2.imshow('Emotion Recognition', frame)\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "def detect_faces(image):\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "    faces = face_cascade.detectMultiScale(image, scaleFactor=1.1, minNeighbors=5)\n",
        "    return faces\n",
        "\n",
        "emotion_recognition()\n"
      ],
      "metadata": {
        "id": "9Kt_Xp134D8D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}